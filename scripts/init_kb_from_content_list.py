#!/usr/bin/env python
"""
ä»å·²æœ‰çš„ content list åˆå§‹åŒ–çŸ¥è¯†åº“ï¼ˆè·³è¿‡ MinerU è§£æï¼‰

ç”¨æ³•:
    python scripts/init_kb_from_content_list.py

è¿™ä¸ªè„šæœ¬ä¼š:
1. è¯»å– hybrid_auto æ–‡ä»¶å¤¹ä¸­çš„ content_list.json
2. åˆ›å»ºåä¸º "calc" çš„çŸ¥è¯†åº“
3. ç›´æ¥æ’å…¥ content list åˆ° LightRAGï¼ˆè·³è¿‡ PDF è§£æï¼‰
"""

import asyncio
import json
import os
import sys
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# æ·»åŠ  RAG-Anything è·¯å¾„
raganything_path = project_root.parent / "RAG-Anything"
if raganything_path.exists():
    sys.path.insert(0, str(raganything_path))

from dotenv import load_dotenv
load_dotenv(dotenv_path=project_root / ".env", override=False)

from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc
from raganything import RAGAnything, RAGAnythingConfig

# ============== é…ç½® ==============
KB_NAME = "calc"  # çŸ¥è¯†åº“åç§°
CONTENT_LIST_PATH = Path("/Users/howard/Documents/forks/hybrid_auto/calculus1-3_content_list.json")
IMAGES_DIR = Path("/Users/howard/Documents/forks/hybrid_auto/images")
SOURCE_FILE_NAME = "calculus1-3.pdf"  # ç”¨äºå¼•ç”¨çš„æºæ–‡ä»¶å

# çŸ¥è¯†åº“è¾“å‡ºç›®å½•
KB_BASE_DIR = project_root / "data" / "knowledge_bases"
# ================================


def get_env_config():
    """è·å–ç¯å¢ƒå˜é‡é…ç½®"""
    return {
        "api_key": os.environ.get("LLM_BINDING_API_KEY", ""),
        "base_url": os.environ.get("LLM_BINDING_HOST", ""),
        "llm_model": os.environ.get("LLM_BINDING_MODEL", "qwen-plus"),
        "embed_model": os.environ.get("EMBEDDING_MODEL", "text-embedding-v3"),
        "embed_dim": int(os.environ.get("EMBEDDING_DIM", "1024")),
    }


def fix_image_paths(content_list: list, images_dir: Path) -> list:
    """
    ä¿®å¤ content list ä¸­çš„å›¾ç‰‡è·¯å¾„ä¸ºç»å¯¹è·¯å¾„
    """
    fixed_list = []
    for item in content_list:
        if item.get("type") == "image":
            img_path = item.get("img_path", "")
            if img_path and not os.path.isabs(img_path):
                # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
                abs_path = str(images_dir / Path(img_path).name)
                item = item.copy()
                item["img_path"] = abs_path
        fixed_list.append(item)
    return fixed_list


async def init_knowledge_base():
    """åˆå§‹åŒ–çŸ¥è¯†åº“"""
    print("\n" + "=" * 60)
    print(f"ğŸš€ ä» Content List åˆå§‹åŒ–çŸ¥è¯†åº“: {KB_NAME}")
    print("=" * 60 + "\n")
    
    # 1. æ£€æŸ¥ content list æ–‡ä»¶
    if not CONTENT_LIST_PATH.exists():
        print(f"âŒ Content list æ–‡ä»¶ä¸å­˜åœ¨: {CONTENT_LIST_PATH}")
        return
    
    print(f"ğŸ“„ Content List: {CONTENT_LIST_PATH}")
    print(f"ğŸ–¼ï¸  Images Dir: {IMAGES_DIR}")
    
    # 2. è¯»å– content list
    print("\nğŸ“– è¯»å– content list...")
    with open(CONTENT_LIST_PATH, "r", encoding="utf-8") as f:
        content_list = json.load(f)
    
    print(f"   æ€»æ¡ç›®æ•°: {len(content_list)}")
    
    # ç»Ÿè®¡å†…å®¹ç±»å‹
    type_counts = {}
    for item in content_list:
        t = item.get("type", "unknown")
        type_counts[t] = type_counts.get(t, 0) + 1
    print(f"   ç±»å‹åˆ†å¸ƒ: {type_counts}")
    
    # 3. ä¿®å¤å›¾ç‰‡è·¯å¾„
    print("\nğŸ”§ ä¿®å¤å›¾ç‰‡è·¯å¾„...")
    content_list = fix_image_paths(content_list, IMAGES_DIR)
    
    # 4. åˆ›å»ºçŸ¥è¯†åº“ç›®å½•
    kb_dir = KB_BASE_DIR / KB_NAME
    rag_storage_dir = kb_dir / "rag_storage"
    rag_storage_dir.mkdir(parents=True, exist_ok=True)
    print(f"\nğŸ“ çŸ¥è¯†åº“ç›®å½•: {kb_dir}")
    
    # 5. è·å– API é…ç½®
    env_config = get_env_config()
    api_key = env_config["api_key"]
    base_url = env_config["base_url"]
    llm_model = env_config["llm_model"]
    embed_model = env_config["embed_model"]
    embed_dim = env_config["embed_dim"]
    
    if not api_key:
        print("âŒ æœªè®¾ç½® LLM_BINDING_API_KEY ç¯å¢ƒå˜é‡")
        return
    
    print(f"\nâš™ï¸  LLM Model: {llm_model}")
    print(f"âš™ï¸  Embed Model: {embed_model}")
    print(f"âš™ï¸  Embed Dim: {embed_dim}")
    
    # 6. é…ç½® RAGAnything
    config = RAGAnythingConfig(
        working_dir=str(rag_storage_dir),
        enable_image_processing=True,
        enable_table_processing=True,
        enable_equation_processing=True,
    )
    
    # 7. å®šä¹‰ LLM å‡½æ•°
    def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
        return openai_complete_if_cache(
            llm_model,
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )
    
    # 8. å®šä¹‰ Vision Model å‡½æ•°ï¼ˆæ”¯æŒ image_data å’Œ messages å‚æ•°ï¼‰
    def vision_model_func(
        prompt,
        system_prompt=None,
        history_messages=[],
        image_data=None,
        messages=None,
        **kwargs,
    ):
        # æ¸…ç† kwargs ä¸­çš„é‡å¤å‚æ•°
        clean_kwargs = {
            k: v
            for k, v in kwargs.items()
            if k not in ["messages", "prompt", "system_prompt", "history_messages"]
        }
        
        # å¦‚æœæä¾›äº† messages æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
        if messages:
            return openai_complete_if_cache(
                llm_model,
                prompt="",
                system_prompt=None,
                history_messages=[],
                messages=messages,
                api_key=api_key,
                base_url=base_url,
                **clean_kwargs,
            )
        
        # å¦‚æœæä¾›äº† image_dataï¼ˆbase64 ç¼–ç çš„å›¾ç‰‡ï¼‰
        if image_data:
            vision_messages = []
            if system_prompt:
                vision_messages.append({"role": "system", "content": system_prompt})
            vision_messages.append({
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_data}"
                        },
                    },
                ],
            })
            return openai_complete_if_cache(
                llm_model,
                prompt="",
                system_prompt=None,
                history_messages=[],
                messages=vision_messages,
                api_key=api_key,
                base_url=base_url,
                **clean_kwargs,
            )
        
        # çº¯æ–‡æœ¬æ ¼å¼
        return llm_model_func(prompt, system_prompt, history_messages, **kwargs)
    
    async def embedding_func(texts):
        return await openai_embed(
            texts,
            model=embed_model,
            api_key=api_key,
            base_url=base_url,
        )
    
    # 9. åˆ›å»º RAGAnything å®ä¾‹
    print("\nğŸ”„ åˆå§‹åŒ– RAGAnything...")
    rag = RAGAnything(
        config=config,
        llm_model_func=llm_model_func,
        vision_model_func=vision_model_func,  # ä½¿ç”¨æ”¯æŒ image_data çš„ vision å‡½æ•°
        embedding_func=EmbeddingFunc(
            embedding_dim=embed_dim,
            max_token_size=8192,
            func=embedding_func,
        ),
    )
    
    # 10. åˆå§‹åŒ– LightRAG
    print("ğŸ”„ åˆå§‹åŒ– LightRAG...")
    await rag._ensure_lightrag_initialized()
    
    # 11. æ’å…¥ content listï¼ˆè·³è¿‡ MinerU è§£æï¼ï¼‰
    print(f"\nğŸ“¥ æ’å…¥ content list åˆ°çŸ¥è¯†åº“...")
    print(f"   è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
    
    start_time = datetime.now()
    
    await rag.insert_content_list(
        content_list=content_list,
        file_path=SOURCE_FILE_NAME,
        display_stats=True,
    )
    
    elapsed = (datetime.now() - start_time).total_seconds()
    print(f"\nâ±ï¸  è€—æ—¶: {elapsed:.1f} ç§’")
    
    # 12. åˆ›å»º metadata.json
    metadata = {
        "kb_name": KB_NAME,
        "created_at": datetime.now().isoformat(),
        "source_file": SOURCE_FILE_NAME,
        "content_list_path": str(CONTENT_LIST_PATH),
        "total_items": len(content_list),
        "type_distribution": type_counts,
        "initialization_method": "content_list_direct",
    }
    
    metadata_path = kb_dir / "metadata.json"
    with open(metadata_path, "w", encoding="utf-8") as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… çŸ¥è¯†åº“åˆå§‹åŒ–å®Œæˆ!")
    print(f"   çŸ¥è¯†åº“è·¯å¾„: {kb_dir}")
    print(f"   RAG å­˜å‚¨: {rag_storage_dir}")
    print(f"   Metadata: {metadata_path}")
    print("\n" + "=" * 60 + "\n")


if __name__ == "__main__":
    asyncio.run(init_knowledge_base())
